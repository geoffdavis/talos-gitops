apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: kube-prometheus-stack
  namespace: monitoring
spec:
  interval: 30m
  timeout: 30m
  install:
    timeout: 30m
    remediation:
      retries: 3
  upgrade:
    timeout: 30m
    remediation:
      retries: 3
      remediateLastFailure: true
    cleanupOnFail: true
  rollback:
    timeout: 20m
    cleanupOnFail: true
  chart:
    spec:
      chart: kube-prometheus-stack
      version: "75.18.1"
      sourceRef:
        kind: HelmRepository
        name: prometheus-community
        namespace: flux-system
      interval: 12h
  values:
    alertmanager:
      enabled: true
      service:
        type: LoadBalancer
        annotations:
          io.cilium/lb-ipam-pool: "bgp-default"
        labels:
          io.cilium/lb-ipam-pool: "bgp-default"

    prometheus:
      service:
        type: ClusterIP
        # Removed LoadBalancer configuration - access via kubectl port-forward only
        # annotations:
        #   io.cilium/lb-ipam-pool: "bgp-default"
        # labels:
        #   io.cilium/lb-ipam-pool: "bgp-default"

      prometheusSpec:
        storageSpec:
          volumeClaimTemplate:
            metadata:
              labels:
                backup-tier: "critical"
                backup-group: "monitoring"
                app: "prometheus"
            spec:
              storageClassName: longhorn
              accessModes: ["ReadWriteOnce"]
              resources:
                requests:
                  storage: 50Gi

        nodeSelector:
          kubernetes.io/os: linux

        tolerations:
          - key: node-role.kubernetes.io/control-plane
            operator: Exists
            effect: NoSchedule
          - key: node-role.kubernetes.io/master
            operator: Exists
            effect: NoSchedule

    grafana:
      # Fix Multi-Attach error by using Recreate strategy for RWO volumes
      deploymentStrategy:
        type: Recreate

      service:
        type: LoadBalancer
        annotations:
          io.cilium/lb-ipam-pool: "bgp-default"
          external-dns.alpha.kubernetes.io/hostname: "grafana.k8s.home.geoffdavis.com"
          external-dns.alpha.kubernetes.io/ttl: "300"
        labels:
          io.cilium/lb-ipam-pool: "bgp-default"

      persistence:
        enabled: true
        storageClassName: longhorn
        size: 10Gi
        annotations:
          backup-tier: "critical"
          backup-group: "monitoring"
          app: "grafana"

      # Native OIDC Authentication Configuration
      env:
        GF_AUTH_GENERIC_OAUTH_ENABLED: "true"
        GF_AUTH_GENERIC_OAUTH_NAME: "Authentik"
        GF_AUTH_GENERIC_OAUTH_CLIENT_ID: "grafana"
        GF_AUTH_GENERIC_OAUTH_SCOPES: "openid profile email"
        GF_AUTH_GENERIC_OAUTH_AUTH_URL: "https://authentik.k8s.home.geoffdavis.com/application/o/authorize/"
        GF_AUTH_GENERIC_OAUTH_TOKEN_URL: "https://authentik.k8s.home.geoffdavis.com/application/o/token/"
        GF_AUTH_GENERIC_OAUTH_API_URL: "https://authentik.k8s.home.geoffdavis.com/application/o/userinfo/"
        GF_AUTH_GENERIC_OAUTH_ALLOW_SIGN_UP: "true"
        GF_AUTH_GENERIC_OAUTH_AUTO_LOGIN: "false"
        GF_AUTH_GENERIC_OAUTH_ROLE_ATTRIBUTE_PATH: >-
          contains(groups[*], 'Grafana Admins') && 'Admin' ||
          contains(groups[*], 'Grafana Editors') && 'Editor' || 'Viewer'
        GF_AUTH_GENERIC_OAUTH_ROLE_ATTRIBUTE_STRICT: "false"
        GF_AUTH_GENERIC_OAUTH_ALLOW_ASSIGN_GRAFANA_ADMIN: "true"
        GF_AUTH_GENERIC_OAUTH_SKIP_ORG_ROLE_SYNC: "false"
        # Disable anonymous access when OIDC is enabled
        GF_AUTH_ANONYMOUS_ENABLED: "false"
        # Security settings
        GF_AUTH_GENERIC_OAUTH_TLS_SKIP_VERIFY_INSECURE: "false"
        GF_AUTH_GENERIC_OAUTH_USE_PKCE: "true"

      envFromSecrets:
        - name: grafana-oidc-secret
          keys:
            - key: client-secret
              name: GF_AUTH_GENERIC_OAUTH_CLIENT_SECRET

      # Init container for OIDC setup
      initContainers:
        - name: setup-grafana-oidc
          image: 1password/op:2
          imagePullPolicy: IfNotPresent
          securityContext:
            runAsNonRoot: true
            runAsUser: 65534
            runAsGroup: 65534
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
            capabilities:
              drop:
                - ALL
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: AUTHENTIK_HOST
              value: "http://authentik-server.authentik.svc.cluster.local:80"
            - name: AUTHENTIK_TOKEN
              valueFrom:
                secretKeyRef:
                  name: authentik-admin-token
                  key: token
            - name: OP_CONNECT_HOST
              value: "http://onepassword-connect.external-secrets.svc.cluster.local:8080"
            - name: OP_CONNECT_TOKEN
              valueFrom:
                secretKeyRef:
                  name: onepassword-connect-token
                  key: token
          volumeMounts:
            - name: tmp-volume
              mountPath: /tmp
          command:
            - /bin/sh
            - -c
            - |
              set -e
              echo "=== Setting up Grafana OIDC Application in Authentik ==="

              # Install curl for API calls
              apk add --no-cache curl

              # Test Authentik API connectivity
              echo "Testing Authentik API connectivity..."
              if ! curl -s -f "${AUTHENTIK_HOST}/api/v3/core/users/me/" \
                -H "Authorization: Bearer ${AUTHENTIK_TOKEN}" > /tmp/api_test.json; then
                echo "WARNING: Failed to connect to Authentik API, skipping OIDC setup"
                echo "Grafana will start without OIDC configuration"
                exit 0
              fi
              echo "API connectivity test successful"

              # Check if Grafana OIDC provider already exists
              echo "Checking for existing Grafana OIDC application..."
              curl -s "${AUTHENTIK_HOST}/api/v3/providers/oauth2/?name=Grafana%20OIDC" \
                -H "Authorization: Bearer ${AUTHENTIK_TOKEN}" > /tmp/existing_provider.json

              EXISTING_COUNT=$(cat /tmp/existing_provider.json | grep -o '"count":[0-9]*' | cut -d':' -f2)
              if [ "$EXISTING_COUNT" != "0" ]; then
                echo "Grafana OIDC provider already exists, skipping setup"
                exit 0
              fi

              # Get default authorization flow
              echo "Getting default authorization flow..."
              curl -s "${AUTHENTIK_HOST}/api/v3/flows/instances/?slug=default-authentication-flow" \
                -H "Authorization: Bearer ${AUTHENTIK_TOKEN}" > /tmp/auth_flow.json

              AUTH_FLOW_UUID=$(cat /tmp/auth_flow.json | grep -o '"pk":"[^"]*"' | head -1 | cut -d'"' -f4)
              if [ -z "$AUTH_FLOW_UUID" ]; then
                echo "WARNING: Could not find default authorization flow, skipping OIDC setup"
                exit 0
              fi

              # Create OAuth2/OIDC provider for Grafana
              echo "Creating Grafana OAuth2/OIDC provider..."
              curl -s -X POST "${AUTHENTIK_HOST}/api/v3/providers/oauth2/" \
                -H "Authorization: Bearer ${AUTHENTIK_TOKEN}" \
                -H "Content-Type: application/json" \
                -d '{
                  "name": "Grafana OIDC",
                  "authorization_flow": "'$AUTH_FLOW_UUID'",
                  "client_type": "confidential",
                  "client_id": "grafana",
                  "redirect_uris": "https://grafana.k8s.home.geoffdavis.com/login/generic_oauth",
                  "sub_mode": "hashed_user_id",
                  "include_claims_in_id_token": true,
                  "issuer_mode": "per_provider"
                }' > /tmp/provider_response.json

              if [ $? -eq 0 ]; then
                CLIENT_SECRET=$(cat /tmp/provider_response.json | grep -o '"client_secret":"[^"]*"' | cut -d'"' -f4)
                PROVIDER_ID=$(cat /tmp/provider_response.json | grep -o '"pk":[0-9]*' | cut -d':' -f2)

                # Create application
                curl -s -X POST "${AUTHENTIK_HOST}/api/v3/core/applications/" \
                  -H "Authorization: Bearer ${AUTHENTIK_TOKEN}" \
                  -H "Content-Type: application/json" \
                  -d '{
                    "name": "Grafana",
                    "slug": "grafana",
                    "provider": '$PROVIDER_ID',
                    "meta_launch_url": "https://grafana.k8s.home.geoffdavis.com"
                  }' > /tmp/application_response.json

                # Store client secret in 1Password
                if [ -n "$CLIENT_SECRET" ]; then
                  echo "Storing client secret in 1Password..."
                  op item create --category=password \
                    --title="home-ops-grafana-oidc-client-secret" \
                    --vault="Automation" \
                    credential="$CLIENT_SECRET" \
                    --tags="kubernetes,home-ops,grafana,oidc" || echo "Failed to create 1Password entry"
                fi

                echo "Grafana OIDC setup completed successfully"
              else
                echo "WARNING: Failed to create OAuth2 provider, Grafana will start without OIDC"
              fi
          resources:
            requests:
              memory: "64Mi"
              cpu: "50m"
            limits:
              memory: "128Mi"
              cpu: "100m"

      # Add volume for init container
      extraVolumes:
        - name: tmp-volume
          emptyDir: {}

      # Ingress configuration for direct OIDC access
      ingress:
        enabled: true
        ingressClassName: nginx-internal
        annotations:
          cert-manager.io/cluster-issuer: letsencrypt-prod
          nginx.ingress.kubernetes.io/ssl-redirect: "true"
          nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
        hosts:
          - grafana.k8s.home.geoffdavis.com
        tls:
          - secretName: grafana-tls # pragma: allowlist secret
            hosts:
              - grafana.k8s.home.geoffdavis.com

      # Fix pod security policy violations
      securityContext:
        runAsNonRoot: true
        runAsUser: 472
        runAsGroup: 472
        fsGroup: 472
        seccompProfile:
          type: RuntimeDefault

      containerSecurityContext:
        allowPrivilegeEscalation: false
        readOnlyRootFilesystem: false
        runAsNonRoot: true
        runAsUser: 472
        runAsGroup: 472
        capabilities:
          drop:
            - ALL
        seccompProfile:
          type: RuntimeDefault

      # Disable the problematic init container and use fsGroup instead
      initChownData:
        enabled: false

      nodeSelector:
        kubernetes.io/os: linux

      tolerations:
        - key: node-role.kubernetes.io/control-plane
          operator: Exists
          effect: NoSchedule
        - key: node-role.kubernetes.io/master
          operator: Exists
          effect: NoSchedule
